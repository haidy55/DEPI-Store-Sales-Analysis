{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Store Sales Dataset Analysis **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Importing Libraries and extracting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Data\n",
    "file_path = r\"c:\\Users\\Lenovo\\Desktop\\Depi Superstore Sales Analysis\\Final Data Cleaning\\Original Store Sales Dataset.xlsx\"\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID           Order Date            Ship Date  \\\n",
      "0       1  CA-2017-152156  2017-08-11 00:00:00  2017-11-11 00:00:00   \n",
      "1       2  CA-2017-152156  2017-08-11 00:00:00  2017-11-11 00:00:00   \n",
      "2       3  CA-2017-138688  2017-12-06 00:00:00           16/06/2017   \n",
      "3       4  US-2016-108966  2016-11-10 00:00:00           18/10/2016   \n",
      "4       5  US-2016-108966  2016-11-10 00:00:00           18/10/2016   \n",
      "\n",
      "        Ship Mode Customer ID    Customer Name    Segment        Country  \\\n",
      "0    Second Class    CG-12520      Claire Gute   Consumer  United States   \n",
      "1    Second Class    CG-12520      Claire Gute   Consumer  United States   \n",
      "2    Second Class    DV-13045  Darrin Van Huff  Corporate  United States   \n",
      "3  Standard Class    SO-20335   Sean O'Donnell   Consumer  United States   \n",
      "4  Standard Class    SO-20335   Sean O'Donnell   Consumer  United States   \n",
      "\n",
      "              City       State  Postal Code Region       Product ID  \\\n",
      "0        Henderson    Kentucky      42420.0  South  FUR-BO-10001798   \n",
      "1        Henderson    Kentucky      42420.0  South  FUR-CH-10000454   \n",
      "2      Los Angeles  California      90036.0   West  OFF-LA-10000240   \n",
      "3  Fort Lauderdale     Florida      33311.0  South  FUR-TA-10000577   \n",
      "4  Fort Lauderdale     Florida      33311.0  South  OFF-ST-10000760   \n",
      "\n",
      "          Category Sub-Category  \\\n",
      "0        Furniture    Bookcases   \n",
      "1        Furniture       Chairs   \n",
      "2  Office Supplies       Labels   \n",
      "3        Furniture       Tables   \n",
      "4  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  \n",
      "0                  Bush Somerset Collection Bookcase  261.9600  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID             int64\n",
      "Order ID          object\n",
      "Order Date        object\n",
      "Ship Date         object\n",
      "Ship Mode         object\n",
      "Customer ID       object\n",
      "Customer Name     object\n",
      "Segment           object\n",
      "Country           object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code      float64\n",
      "Region            object\n",
      "Product ID        object\n",
      "Category          object\n",
      "Sub-Category      object\n",
      "Product Name      object\n",
      "Sales            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check Data type \n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convet empty strings to NaN for the entire DataFrame\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Row ID            0\n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "Country           0\n",
      "City              0\n",
      "State             0\n",
      "Postal Code      11\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values across all columns\n",
    "# Display missing values for each column\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            City    State\n",
      "2234  Burlington  Vermont\n",
      "5274  Burlington  Vermont\n",
      "8798  Burlington  Vermont\n",
      "9146  Burlington  Vermont\n",
      "9147  Burlington  Vermont\n",
      "9148  Burlington  Vermont\n",
      "9386  Burlington  Vermont\n",
      "9387  Burlington  Vermont\n",
      "9388  Burlington  Vermont\n",
      "9389  Burlington  Vermont\n",
      "9741  Burlington  Vermont\n"
     ]
    }
   ],
   "source": [
    "# Check rows where Postal Code is missing and identify the city\n",
    "missing_postal_code_rows = data[data['Postal Code'].isnull()]\n",
    "print(missing_postal_code_rows[['City', 'State']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Postal Code' column to string to preserve leading zeros\n",
    "data['Postal Code'] = data['Postal Code'].astype(str)\n",
    "\n",
    "# Remove decimal points\n",
    "data['Postal Code'] = data['Postal Code'].str.replace('.0', '', regex=False)\n",
    "\n",
    "# Handle missing values by replacing 'nan' with None\n",
    "data['Postal Code'] = data['Postal Code'].replace('nan', None)\n",
    "\n",
    "State_name = 'Vermont'\n",
    "postal_code_for_State = '05407'\n",
    "\n",
    "# Fill missing Postal Code for that State\n",
    "data.loc[(data['State'] == State_name) & (data['Postal Code'].isnull()), 'Postal Code'] = postal_code_for_State\n",
    "\n",
    "# Verify that missing postal codes are filled\n",
    "print(data['Postal Code'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Date    datetime64[ns]\n",
      "Ship Date     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 'Order Date' and 'Ship Date' to datetime format\n",
    "data['Order Date'] = pd.to_datetime(data['Order Date'], errors='coerce')\n",
    "data['Ship Date'] = pd.to_datetime(data['Ship Date'], errors='coerce')\n",
    "\n",
    "# Check for any issues after conversion\n",
    "print(data[['Order Date', 'Ship Date']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove for duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data.duplicated()\n",
    "\n",
    "# Remove duplicates if found\n",
    "data_cleaned = data.drop_duplicates()\n",
    "\n",
    "print(f\"Number of duplicates removed: {sum(duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical columns to category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship Mode       category\n",
      "Category        category\n",
      "Sub-Category    category\n",
      "Region          category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['Ship Mode', 'Category', 'Sub-Category', 'Region']\n",
    "data[categorical_columns] = data[categorical_columns].astype('category')\n",
    "\n",
    "# Verify conversion\n",
    "print(data[categorical_columns].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to c:\\Users\\Lenovo\\Desktop\\Depi Superstore Sales Analysis\\Final Data Cleaning\\Clean Data.xlsx\n"
     ]
    }
   ],
   "source": [
    "#  Finally : Save the cleaned dataset to a new Excel file\n",
    "\n",
    "cleaned_file_path = r\"c:\\Users\\Lenovo\\Desktop\\Depi Superstore Sales Analysis\\Final Data Cleaning\\Clean Data.xlsx\"\n",
    "data_cleaned.to_excel(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
